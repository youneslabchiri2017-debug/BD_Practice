{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7656d4",
   "metadata": {},
   "source": [
    "# Spark Practical Work\n",
    "\n",
    "Authors:\n",
    " - Ahajjan Ziggaf Kanjaa, Mohammed\n",
    " - Labchiri Boukhalef, Younes\n",
    " - Ramírez Castaño, Víctor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ecea7",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "187cb106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:10.375459Z",
     "start_time": "2025-12-11T19:53:10.018559Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (col, sum)\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    SQLTransformer,\n",
    "    StringIndexer, \n",
    "    OneHotEncoder, \n",
    "    VectorAssembler, \n",
    "    StandardScaler\n",
    ")\n",
    "from pyspark.ml.regression import (\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor\n",
    ")\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import gc\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName(\"FlightModelPrediction\").getOrCreate()\n",
    "\n",
    "data_path = \"../training_data/flight_data/\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    data_path,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    nullValue=\"NA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67259b23",
   "metadata": {},
   "source": [
    "### Explaratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57fdac5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:11.960721Z",
     "start_time": "2025-12-11T19:53:10.384056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: integer (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------+--------+-----------------+------------------+------------------+-------------------+----------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+\n",
      "|summary|             Year|             Month|        DayofMonth|         DayOfWeek|           DepTime|        CRSDepTime|          ArrTime|        CRSArrTime|UniqueCarrier|         FlightNum|           TailNum| ActualElapsedTime|    CRSElapsedTime|           AirTime|          ArrDelay|          DepDelay|  Origin|    Dest|         Distance|            TaxiIn|           TaxiOut|          Cancelled|CancellationCode|            Diverted|      CarrierDelay|      WeatherDelay|          NASDelay|       SecurityDelay|LateAircraftDelay|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------+--------+-----------------+------------------+------------------+-------------------+----------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+\n",
      "|  count|         17696001|          17696001|          17696001|          17696001|          17395368|          17696001|         17350625|          17696001|     17696001|          17696001|          12493905|          17350625|          17691351|          12213128|          17350625|          17395368|17696001|17696001|         17684899|          12493905|          12493905|           17696001|          121934|            17696001|           7141922|           7141922|           7141922|             7141922|          7141922|\n",
      "|   mean| 1997.68413485058| 6.537741436610452|15.743730857610146|3.9464985337647756|1351.7598990144963|1336.4536160457947|1493.109646309571|1489.3580469960416|         NULL|1385.4389413743818|2.9287337375640194|117.59346288678361|118.09298492805891|101.51477115444953|  8.34789386549476| 9.059763150742198|    NULL|    NULL|686.2674647449217| 6.384745041682324|14.955017106341051|0.01698875356076212|            NULL|0.002528424359831354| 3.396185788643449|0.6796269967664167| 3.585969575136777|0.030995997996057643|4.515005344499702|\n",
      "| stddev|7.505780608178111|3.4367261892677443| 8.792355437056468|1.9914717704902312|476.26580196599036| 474.6904847651953|497.3035550093118|490.61543215260735|         NULL|1502.0807590031702| 17.87300921355486| 68.02204012814099|  67.3249965790229| 71.27953671846778|31.273321790655014|29.077855816043296|    NULL|    NULL|545.6549366717261|23.700583479290366|10.598928825905219|0.12922900896059428|            NULL|0.050219832462960336|18.800458066605923| 8.492678450038207|15.627948483953032|  1.2779188178036067|19.86007624277382|\n",
      "|    min|             1988|                 1|                 1|                 1|                 1|                 0|                1|                 0|           AA|                 1|                 0|              -530|               -97|             -1425|             -1426|             -1200|     ABE|     ABE|               10|                 0|                 0|                  0|               A|                   0|                 0|                 0|                 0|                   0|                0|\n",
      "|    max|             2006|                12|                31|                 7|              2930|              2400|             2955|              2400|           YV|              9619|            XXXXXX|              1879|              1592|              1958|              1779|              1752|     YUM|     YUM|             4983|              1501|               602|                  1|               D|                   1|              1666|              1163|              1392|                 354|             1366|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------+--------+-----------------+------------------+------------------+-------------------+----------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+\n",
      "\n",
      "\n",
      "Column: UniqueCarrier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|UniqueCarrier|  count|\n",
      "+-------------+-------+\n",
      "|           DL|2148375|\n",
      "|           WN|2119162|\n",
      "|           AA|1993893|\n",
      "|           UA|1822418|\n",
      "|           US|1727761|\n",
      "+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column: Origin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Origin| count|\n",
      "+------+------+\n",
      "|   ORD|941464|\n",
      "|   ATL|909311|\n",
      "|   DFW|767363|\n",
      "|   LAX|587592|\n",
      "|   DEN|525346|\n",
      "+------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column: Dest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Dest| count|\n",
      "+----+------+\n",
      "| ORD|944812|\n",
      "| ATL|906945|\n",
      "| DFW|770945|\n",
      "| LAX|587727|\n",
      "| DEN|527690|\n",
      "+----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column: TailNum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|TailNum|  count|\n",
      "+-------+-------+\n",
      "|   NULL|5202096|\n",
      "| UNKNOW|  86731|\n",
      "|      0|  72705|\n",
      "| 000000|  10009|\n",
      "|   N528|   6486|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column: CancellationCode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|CancellationCode|   count|\n",
      "+----------------+--------+\n",
      "|            NULL|17574067|\n",
      "|               A|   55655|\n",
      "|               B|   37913|\n",
      "|               C|   28209|\n",
      "|               D|     157|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 190:=========================================>             (12 + 4) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn |TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|0   |0    |0         |0        |300633 |0         |345376 |0         |0            |0        |5202096|345376           |4650          |5482873|345376  |300633  |0     |0   |11102   |5202096|5202096|0        |17574067        |0       |10554079    |10554079    |10554079|10554079     |10554079         |\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n",
    "cat_cols = [\n",
    "    \"UniqueCarrier\",\n",
    "    \"Origin\",\n",
    "    \"Dest\",\n",
    "    \"TailNum\",\n",
    "    \"CancellationCode\"\n",
    "]\n",
    "\n",
    "# Variable info for numerical variables\n",
    "df.describe().show()\n",
    "\n",
    "# Variable info for categorical variables\n",
    "for c in cat_cols:\n",
    "    print(f\"\\nColumn: {c}\")\n",
    "    df.groupBy(c).count() \\\n",
    "        .orderBy(\"count\", ascending=False) \\\n",
    "        .show(5)\n",
    "\n",
    "# Show null values\n",
    "df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in df.columns\n",
    "]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754059ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split 80/20\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb205e0",
   "metadata": {},
   "source": [
    "### Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f1c0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not control that any of this variables has a null value, so if an instance has a null value, it is deleted\n",
    "sql_logic = \"\"\"\n",
    "SELECT Year,\n",
    "       Month,\n",
    "       DayofMonth,\n",
    "       DayOfWeek,\n",
    "       DepTime,\n",
    "       CRSDepTime,\n",
    "       ArrTime,\n",
    "       CRSArrTime,\n",
    "       UniqueCarrier,\n",
    "       FlightNum,\n",
    "       TailNum,\n",
    "       ActualElapsedTime,\n",
    "       CRSElapsedTime,\n",
    "       AirTime,\n",
    "       ArrDelay,\n",
    "       DepDelay,\n",
    "       Origin,\n",
    "       Dest,\n",
    "       Distance,\n",
    "       TaxiIn,\n",
    "       Cancelled,\n",
    "       CancellationCode,\n",
    "       Diverted,\n",
    "       CarrierDelay,\n",
    "       WeatherDelay,\n",
    "       NASDelay,\n",
    "       SecurityDelay,\n",
    "       LateAircraftDelay,\n",
    "       CAST(TaxiOut AS INT) AS TaxiOut\n",
    "FROM __THIS__\n",
    "WHERE CRSDepTime IS NOT NULL\n",
    "  AND CRSArrTime IS NOT NULL\n",
    "  AND ArrDelay IS NOT NULL\n",
    "  AND Year IS NOT NULL\n",
    "  AND Month IS NOT NULL\n",
    "  AND DayofMonth IS NOT NULL\n",
    "  AND DayOfWeek IS NOT NULL\n",
    "  AND UniqueCarrier IS NOT NULL\n",
    "  AND CRSElapsedTime IS NOT NULL\n",
    "  AND DepDelay IS NOT NULL\n",
    "  AND Origin IS NOT NULL\n",
    "  AND Dest IS NOT NULL\n",
    "  AND Distance IS NOT NULL\n",
    "  AND Cancelled != 1 -- A cancelled flight is not considered a delay, so that it does not give us useful information.\n",
    "\"\"\"\n",
    "sql_clean = SQLTransformer(statement=sql_logic)\n",
    "\n",
    "stages.append(sql_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1cb16",
   "metadata": {},
   "source": [
    "### Feature engineering and selection\n",
    "The following SQL query fills all the missing values of ``TaxiOut`` with its median, also creates 2 new variables: ``TakeOffTime``, which signals the exact moment the plane takes off from the ground, and ``LandingEstimate``, that show a new approximate hour of landing taking into account when the plan took off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef23d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the variables that contain information that is unknown at the time the plane takes off\n",
    "sql_logic = \"\"\"\n",
    "SELECT \n",
    "    Year, Month, DayofMonth, DayOfWeek, DepTime, CRSDepTime, CRSArrTime, UniqueCarrier, CRSElapsedTime, ArrDelay, DepDelay, Origin, Dest, Distance,\n",
    "    -- Mediana de TaxiOut\n",
    "    COALESCE(\n",
    "        (SELECT percentile_approx(TaxiOut, 0.5) FROM __THIS__), \n",
    "        0\n",
    "    ) AS TaxiOut,\n",
    "\n",
    "    -- Timestamp base\n",
    "    CASE\n",
    "        WHEN CRSDepTime = 2400 THEN\n",
    "            to_timestamp(\n",
    "                concat(\n",
    "                    Year,\n",
    "                    lpad(Month, 2, '0'),\n",
    "                    lpad(DayofMonth + 1, 2, '0'),\n",
    "                    '0000'\n",
    "                ),\n",
    "                'yyyyMMddHHmm'\n",
    "            )\n",
    "        ELSE\n",
    "            to_timestamp(\n",
    "                concat(\n",
    "                    Year,\n",
    "                    lpad(Month, 2, '0'),\n",
    "                    lpad(DayofMonth, 2, '0'),\n",
    "                    lpad(CRSDepTime, 4, '0')\n",
    "                ),\n",
    "                'yyyyMMddHHmm'\n",
    "            )\n",
    "    END AS CRSDepTimestamp,\n",
    "\n",
    "    -- TakeOffTime (HHmm)\n",
    "    CAST(\n",
    "        date_format(\n",
    "            CRSDepTimestamp\n",
    "            + (CAST(DepDelay AS INT)\n",
    "            + CAST(TaxiOut AS INT)) * INTERVAL 1 MINUTE,\n",
    "            'HHmm'\n",
    "        ) AS INT\n",
    "    ) AS TakeOffTime,\n",
    "\n",
    "    -- LandingEst (HHmm)\n",
    "    CAST(\n",
    "        date_format(\n",
    "            CRSDepTimestamp\n",
    "            + (CAST(DepDelay AS INT)\n",
    "            + CAST(TaxiOut AS INT)\n",
    "            + CAST(CRSElapsedTime AS INT)) * INTERVAL 1 MINUTE,\n",
    "            'HHmm'\n",
    "        ) AS INT\n",
    "    ) AS LandingEst\n",
    "\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "sql_trans = SQLTransformer(statement=sql_logic)\n",
    "\n",
    "stages.append(sql_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1f41c",
   "metadata": {},
   "source": [
    "Due to the ``HHmm`` format being not being very useful for machine learning, we are splitting the variables that follow this format into 2 separate variables, one for the hour and another one for the minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddc67e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_sql = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \n",
    "    -- CRSDepTime\n",
    "    CAST(FLOOR(CRSDepTime / 100) AS INT)      AS CRSDepTimeHour,\n",
    "    CAST(CRSDepTime % 100 AS INT)             AS CRSDepTimeMinute,\n",
    "\n",
    "    -- CRSArrTime\n",
    "    CAST(FLOOR(CRSArrTime / 100) AS INT)      AS CRSArrTimeHour,\n",
    "    CAST(CRSArrTime % 100 AS INT)             AS CRSArrTimeMinute,\n",
    "\n",
    "    -- TakeOffTime\n",
    "    CAST(FLOOR(TakeOffTime / 100) AS INT)     AS TakeOffTimeHour,\n",
    "    CAST(TakeOffTime % 100 AS INT)            AS TakeOffTimeMinute,\n",
    "\n",
    "    -- LandingEst\n",
    "    CAST(FLOOR(LandingEst / 100) AS INT)      AS LandingEstHour,\n",
    "    CAST(LandingEst % 100 AS INT)             AS LandingEstMinute,\n",
    "\n",
    "    -- DepTime\n",
    "    CAST(FLOOR(COALESCE(DepTime, CRSDepTime) / 100) AS INT) AS DepTimeHour,\n",
    "    CAST((COALESCE(DepTime, CRSDepTime) % 100) AS INT) AS DepTimeMinute\n",
    "\n",
    "\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "time_splitter = SQLTransformer(statement=time_split_sql)\n",
    "\n",
    "stages.append(time_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f92a8",
   "metadata": {},
   "source": [
    "We drop all the ``HHmm`` variables, as well as the ``CRSDepTimestamp`` since it is just a variable used for creating others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13fa2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_hhmm_sql = \"\"\"\n",
    "SELECT\n",
    "    * EXCEPT (\n",
    "        CRSDepTime,\n",
    "        CRSArrTime,\n",
    "        TakeOffTime,\n",
    "        LandingEst,\n",
    "        DepTime,\n",
    "        CRSDepTimestamp\n",
    "    )\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "drop_hhmm = SQLTransformer(statement=drop_hhmm_sql)\n",
    "stages.append(drop_hhmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42a7fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables selected\n",
    "cat_cols = [\"UniqueCarrier\", \"Origin\", \"Dest\", \"Month\", \"DayOfWeek\", \"DayofMonth\", \"Year\"]\n",
    "\n",
    "# Numerical variables selected\n",
    "num_cols = [\n",
    "    \"DepDelay\", \"TaxiOut\", \"Distance\", \"CRSElapsedTime\", \n",
    "    \"LandingEstMinute\", \"TakeOffTimeMinute\", \"CRSDepTimeMinute\", \"CRSArrTimeMinute\", \"DepTimeMinute\",\n",
    "    \"LandingEstHour\", \"TakeOffTimeHour\", \"CRSDepTimeHour\", \"CRSArrTimeHour\", \"DepTimeHour\"\n",
    "]\n",
    "\n",
    "\n",
    "# Categorical variables encoding\n",
    "input_cols_ohe = []\n",
    "categorical_stages = [] \n",
    "\n",
    "for c in cat_cols:\n",
    "    indexer = StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "    \n",
    "    encoder = OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\")\n",
    "    \n",
    "    categorical_stages += [indexer, encoder]\n",
    "    input_cols_ohe.append(f\"{c}_ohe\")\n",
    "\n",
    "stages += categorical_stages\n",
    "\n",
    "# Numerical variables processing\n",
    "\n",
    "# Grouping the numerical variables to a vector\n",
    "num_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"num_features_raw\", handleInvalid=\"skip\")\n",
    "stages.append(num_assembler)\n",
    "\n",
    "# Standartizing phase\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"num_features_raw\", \n",
    "    outputCol=\"num_features_scaled\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "stages.append(scaler)\n",
    "\n",
    "# Group new columns\n",
    "assembler_all_inputs = input_cols_ohe + [\"num_features_scaled\"]\n",
    "\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=assembler_all_inputs, \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "stages.append(assembler_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad5b74",
   "metadata": {},
   "source": [
    "### Models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c251e966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:18.023080Z",
     "start_time": "2025-12-11T19:53:12.054651Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Models\n",
    "dt = DecisionTreeRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "rf = RandomForestRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "gbt = GBTRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "\n",
    "# Use a separate pipeline for each model\n",
    "pipeline_dt = Pipeline(stages=stages + [dt])\n",
    "pipeline_rf = Pipeline(stages=stages + [rf])\n",
    "pipeline_gbt = Pipeline(stages=stages + [gbt])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645faf1a",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "496c4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "paramGrid_dt = (ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [5])    # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .addGrid(dt.maxBins, [32])    # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .build())\n",
    "\n",
    "paramGrid_rf = (ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [20])   # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .addGrid(rf.maxDepth, [5])    # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .build())\n",
    "\n",
    "paramGrid_gbt = (ParamGridBuilder()\n",
    "    .addGrid(gbt.maxIter, [10])   # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .addGrid(gbt.maxDepth, [3])   # You can add more values if you have the technical muscle to do it. We don’t have it. RAM is very expensive.\n",
    "    .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ceed4",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73fc27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluador = RegressionEvaluator(labelCol=\"ArrDelay\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "cv_dt = CrossValidator(\n",
    "    estimator=pipeline_dt, \n",
    "    estimatorParamMaps=paramGrid_dt,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "cv_gbt = CrossValidator(\n",
    "    estimator=pipeline_gbt,\n",
    "    estimatorParamMaps=paramGrid_gbt,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ead558",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190e246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:18.705094Z",
     "start_time": "2025-12-11T19:53:18.032714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating training for Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_13 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_2 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_5 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_0 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_13 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_12 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_1 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_14 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_11 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_3 to disk instead.\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_4 to disk instead.\n",
      "26/01/06 14:15:28 WARN MemoryStore: Not enough space to cache rdd_675_15 in memory! (computed 347.3 MiB so far)\n",
      "26/01/06 14:15:28 WARN BlockManager: Persisting block rdd_675_15 to disk instead.\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_13 in memory! (computed 526.4 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 526.4 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 815.9 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:47 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 350.0 MiB so far)\n",
      "26/01/06 14:15:49 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 815.9 MiB so far)\n",
      "26/01/06 14:15:49 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 815.9 MiB so far)\n",
      "26/01/06 14:15:49 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 815.9 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 233.3 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 350.0 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 350.0 MiB so far)\n",
      "26/01/06 14:15:53 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 350.0 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:15:57 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 155.5 MiB so far)\n",
      "[Stage 253:=================>                                     (5 + 11) / 16]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#Training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m cv_model \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#Testing\u001b[39;00m\n\u001b[1;32m     19\u001b[0m predicciones \u001b[38;5;241m=\u001b[39m cv_model\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/base.py:203\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    208\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/tuning.py:858\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    852\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    854\u001b[0m tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    855\u001b[0m     inheritable_thread_target(dataset\u001b[38;5;241m.\u001b[39msparkSession),\n\u001b[1;32m    856\u001b[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[1;32m    857\u001b[0m )\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    859\u001b[0m     metrics_all[i][j] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:01 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_4 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_14 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_3 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_2 in memory! (computed 101.7 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_0 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_11 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_1 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_5 in memory! (computed 155.5 MiB so far)\n",
      "26/01/06 14:16:05 WARN MemoryStore: Not enough space to cache rdd_675_12 in memory! (computed 155.5 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "## Assign cross validation to model\n",
    "modelos_cv = [(\"Decision Tree\", cv_dt), (\"Random Forest\", cv_rf), (\"GBT\", cv_gbt)]\n",
    "resultados = []\n",
    "\n",
    "# Evaluator\n",
    "eval_mae = RegressionEvaluator(labelCol=\"ArrDelay\", metricName=\"mae\")\n",
    "\n",
    "for nombre, cv in modelos_cv:\n",
    "    print(f\"Initiating training for {nombre}...\")\n",
    "    \n",
    "    # Clear cache and start garbage collector to gain memory on the JVM\n",
    "    spark.catalog.clearCache()\n",
    "    gc.collect()\n",
    "\n",
    "    #Training\n",
    "    cv_model = cv.fit(train_data) \n",
    "    \n",
    "    #Testing\n",
    "    predicciones = cv_model.transform(test_data)\n",
    "    \n",
    "    #Evaluate result\n",
    "    rmse = evaluador.evaluate(predicciones) \n",
    "    mae = eval_mae.evaluate(predicciones)   \n",
    "    \n",
    "    # Select best evaluator metric\n",
    "    score = mae if rmse > (2 * mae) else rmse\n",
    "    metrica_usada = \"MAE\" if rmse > (2 * mae) else \"RMSE\"\n",
    "    \n",
    "    print(f\"Results {nombre} -> RMSE: {rmse:.2f}, MAE: {mae:.2f} (Score: {score:.2f} using {metrica_usada})\")\n",
    "    \n",
    "    resultados.append({\n",
    "        \"nombre\": nombre,\n",
    "        \"modelo_fit\": cv_model, \n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"score_final\": score,\n",
    "        \"metrica\": metrica_usada\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53649c4f",
   "metadata": {},
   "source": [
    "### Find and save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bdf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mejor_resultado = min(resultados, key=lambda x: x[\"score_final\"])\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Best model: {mejor_resultado['nombre']}\")\n",
    "print(f\"Criteria: {mejor_resultado['metrica']} of {mejor_resultado['score_final']:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Retrive better functioning model\n",
    "mejor_modelo_final = mejor_resultado['modelo_fit'].bestModel\n",
    "\n",
    "# Save the model for app\n",
    "path_guardado = \"best_model\"\n",
    "mejor_modelo_final.write().overwrite().save(path_guardado)\n",
    "\n",
    "print(f\"The model '{mejor_resultado['nombre']}' has been saved at folder '{path_guardado}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
