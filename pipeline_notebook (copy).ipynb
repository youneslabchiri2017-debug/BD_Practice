{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7656d4",
   "metadata": {},
   "source": [
    "# Spark Practical Work\n",
    "\n",
    "Authors:\n",
    " - Ahajjan Ziggaf Kanjaa, Mohammed\n",
    " - Labchiri Boukhalef, Younes\n",
    " - Ramírez Castaño, Víctor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ecea7",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "187cb106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:10.375459Z",
     "start_time": "2025-12-11T19:53:10.018559Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (col, sum)\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    SQLTransformer,\n",
    "    Imputer,\n",
    "    StringIndexer, \n",
    "    OneHotEncoder, \n",
    "    VectorAssembler, \n",
    "    StandardScaler\n",
    ")\n",
    "from pyspark.ml.regression import (\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName(\"FlightModelPrediction\").getOrCreate()\n",
    "\n",
    "data_path = \"../training_data/flight_data/1988.csv\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    data_path,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    nullValue=\"NA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67259b23",
   "metadata": {},
   "source": [
    "### Explaratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57fdac5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:11.960721Z",
     "start_time": "2025-12-11T19:53:10.384056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: integer (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-------------+-----------------+-------+------------------+------------------+-------+------------------+------------------+-------+-------+------------------+------+-------+--------------------+----------------+--------------------+------------+------------+--------+-------------+-----------------+\n",
      "|summary|   Year|             Month|       DayofMonth|         DayOfWeek|           DepTime|        CRSDepTime|          ArrTime|        CRSArrTime|UniqueCarrier|        FlightNum|TailNum| ActualElapsedTime|    CRSElapsedTime|AirTime|          ArrDelay|          DepDelay| Origin|   Dest|          Distance|TaxiIn|TaxiOut|           Cancelled|CancellationCode|            Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+-------+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-------------+-----------------+-------+------------------+------------------+-------+------------------+------------------+-------+-------+------------------+------+-------+--------------------+----------------+--------------------+------------+------------+--------+-------------+-----------------+\n",
      "|  count|5202096|           5202096|          5202096|           5202096|           5151933|           5202096|          5137497|           5202096|      5202096|          5202096|      0|           5137497|           5202096|      0|           5137497|           5151933|5202096|5202096|           5190994|     0|      0|             5202096|               0|             5202096|           0|           0|       0|            0|                0|\n",
      "|   mean| 1988.0| 6.508971383842205|15.75753676979433|3.9543607038393755|1363.7786636588635|1357.0670687353713|1493.591975820132|1493.3827745585625|         NULL|  687.01381308611|   NULL|104.04070698240797|103.98662154639207|   NULL| 6.547350003318737| 6.706767731645578|   NULL|   NULL| 601.5666221151479|  NULL|   NULL|0.009642843961357115|            NULL|0.002775035293466326|        NULL|        NULL|    NULL|         NULL|             NULL|\n",
      "| stddev|    0.0|3.4452009233809564|8.798634504531314|1.9879310442594094| 475.5134685541383|469.70432659492076|493.7432332460107|483.78903391103125|         NULL|518.6402297291613|   NULL| 61.96058482682738|  61.7384365761797|   NULL|23.325170715950783|21.777144381870592|   NULL|   NULL|501.09997680551515|  NULL|   NULL| 0.09772339206897167|            NULL|0.052605465538779615|        NULL|        NULL|    NULL|         NULL|             NULL|\n",
      "|    min|   1988|                 1|                1|                 1|                 1|                 1|                1|                 1|           AA|                1|   NULL|              -530|               -52|   NULL|             -1185|             -1000|    ABE|    ABE|                10|  NULL|   NULL|                   0|            NULL|                   0|        NULL|        NULL|    NULL|         NULL|             NULL|\n",
      "|    max|   1988|                12|               31|                 7|              2400|              2400|             2400|              2400|           WN|             6189|   NULL|              1737|              1560|   NULL|              1394|              1439|    YUM|    YUM|              4983|  NULL|   NULL|                   1|            NULL|                   1|        NULL|        NULL|    NULL|         NULL|             NULL|\n",
      "+-------+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-------------+-----------------+-------+------------------+------------------+-------+------------------+------------------+-------+-------+------------------+------+-------+--------------------+----------------+--------------------+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:=====================================>                 (11 + 5) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn |TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|0   |0    |0         |0        |50163  |0         |64599  |0         |0            |0        |5202096|64599            |0             |5202096|64599   |50163   |0     |0   |11102   |5202096|5202096|0        |5202096         |0       |5202096     |5202096     |5202096 |5202096      |5202096          |\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Drop the variables that contain information that is unknown at the time the plane takes off\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"ArrTime\", \"ActualElapsedTime\", \"AirTime\", \"TaxiIn\",\n",
    "    \"Diverted\", \"CarrierDelay\", \"WeatherDelay\",\n",
    "    \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"\n",
    "]\n",
    "\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "\n",
    "df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in df.columns\n",
    "]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f4200",
   "metadata": {},
   "source": [
    "### Feature selection (FSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "754059ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 249:===>                                                   (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn |TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|0   |0    |0         |0        |0      |0         |0      |0         |0            |0        |5137497|0                |0             |5137497|0       |0       |0     |0   |10999   |5137497|5137497|0        |5137497         |0       |5137497     |5137497     |5137497 |5137497      |5137497          |\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+-------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#A cancelled flight is not considered a delay, so that it does not give us useful information.\n",
    "df = df.filter(col(\"Cancelled\") != 1)\n",
    "\n",
    "#If we do not have the attributes 'CRSDepTime' or 'CRSArrTime' we delete that instance\n",
    "df = df.dropna(subset=[\"CRSDepTime\", \"CRSArrTime\"])\n",
    "\n",
    "df = df.na.drop(subset=[\"ArrDelay\"])\n",
    "\n",
    "df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in df.columns\n",
    "]).show(truncate=False)\n",
    "\n",
    "df = df.withColumn(\"TaxiOut\", col(\"TaxiOut\").cast(\"int\"))\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Construcción del Pipeline ---\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1cb16",
   "metadata": {},
   "source": [
    "### New variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef23d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_logic = \"\"\"\n",
    "SELECT \n",
    "    Year, Month, DayofMonth, DayOfWeek, DepTime, CRSDepTime, CRSArrTime, UniqueCarrier, CRSElapsedTime, ArrDelay, DepDelay, Origin, Dest, Distance,\n",
    "    -- 1. Mediana de TaxiOut (robusta)\n",
    "    COALESCE(\n",
    "        (SELECT percentile_approx(TaxiOut, 0.5) FROM __THIS__), \n",
    "        0\n",
    "    ) AS TaxiOut,\n",
    "\n",
    "    -- 2. Timestamp base CORREGIDO (maneja CRSDepTime = 2400)\n",
    "    CASE\n",
    "        WHEN CRSDepTime = 2400 THEN\n",
    "            to_timestamp(\n",
    "                concat(\n",
    "                    Year,\n",
    "                    lpad(Month, 2, '0'),\n",
    "                    lpad(DayofMonth + 1, 2, '0'),\n",
    "                    '0000'\n",
    "                ),\n",
    "                'yyyyMMddHHmm'\n",
    "            )\n",
    "        ELSE\n",
    "            to_timestamp(\n",
    "                concat(\n",
    "                    Year,\n",
    "                    lpad(Month, 2, '0'),\n",
    "                    lpad(DayofMonth, 2, '0'),\n",
    "                    lpad(CRSDepTime, 4, '0')\n",
    "                ),\n",
    "                'yyyyMMddHHmm'\n",
    "            )\n",
    "    END AS CRSDepTimestamp,\n",
    "\n",
    "    -- 3. TakeOffTime (HHmm)\n",
    "    CAST(\n",
    "        date_format(\n",
    "            CRSDepTimestamp\n",
    "            + (COALESCE(CAST(DepDelay AS INT), 0)\n",
    "            + COALESCE(CAST(TaxiOut AS INT), 0)) * INTERVAL 1 MINUTE,\n",
    "            'HHmm'\n",
    "        ) AS INT\n",
    "    ) AS TakeOffTime,\n",
    "\n",
    "    -- 4. LandingEst (HHmm)\n",
    "    CAST(\n",
    "        date_format(\n",
    "            CRSDepTimestamp\n",
    "            + COALESCE(CAST(CRSElapsedTime AS INT), 0) * INTERVAL 1 MINUTE,\n",
    "            'HHmm'\n",
    "        ) AS INT\n",
    "    ) AS LandingEst\n",
    "\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "# Creamos el transformador\n",
    "sql_trans = SQLTransformer(statement=sql_logic)\n",
    "\n",
    "stages.append(sql_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddc67e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_sql = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \n",
    "    -- CRSDepTime\n",
    "    CAST(FLOOR(CRSDepTime / 100) AS INT)      AS CRSDepTimeHour,\n",
    "    CAST(CRSDepTime % 100 AS INT)             AS CRSDepTimeMinute,\n",
    "\n",
    "    -- CRSArrTime\n",
    "    CAST(FLOOR(CRSArrTime / 100) AS INT)      AS CRSArrTimeHour,\n",
    "    CAST(CRSArrTime % 100 AS INT)             AS CRSArrTimeMinute,\n",
    "\n",
    "    -- TakeOffTime\n",
    "    CAST(FLOOR(TakeOffTime / 100) AS INT)     AS TakeOffTimeHour,\n",
    "    CAST(TakeOffTime % 100 AS INT)            AS TakeOffTimeMinute,\n",
    "\n",
    "    -- LandingEst\n",
    "    CAST(FLOOR(LandingEst / 100) AS INT)      AS LandingEstHour,\n",
    "    CAST(LandingEst % 100 AS INT)             AS LandingEstMinute,\n",
    "\n",
    "    -- DepTime\n",
    "    CAST(FLOOR(DepTime / 100) AS INT)         AS DepTimeHour,\n",
    "    CAST(DepTime % 100 AS INT)                AS DepTimeMinute\n",
    "\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "time_splitter = SQLTransformer(statement=time_split_sql)\n",
    "\n",
    "stages.append(time_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13fa2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_hhmm_sql = \"\"\"\n",
    "SELECT\n",
    "    * EXCEPT (\n",
    "        CRSDepTime,\n",
    "        CRSArrTime,\n",
    "        TakeOffTime,\n",
    "        LandingEst,\n",
    "        DepTime\n",
    "    )\n",
    "FROM __THIS__\n",
    "\"\"\"\n",
    "\n",
    "drop_hhmm = SQLTransformer(statement=drop_hhmm_sql)\n",
    "stages.append(drop_hhmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42a7fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Definición de Variables ---\n",
    "\n",
    "# Selecciona tus 5 variables categóricas (Ejemplos basados en flight data)\n",
    "cat_cols = [\"UniqueCarrier\", \"Origin\", \"Dest\", \"Month\", \"DayOfWeek\", \"DayofMonth\", \"Year\"]\n",
    "\n",
    "# Selecciona tus 10 variables numéricas\n",
    "num_cols = [\n",
    "    \"DepDelay\", \"TaxiOut\", \"Distance\", \"CRSElapsedTime\", \n",
    "    \"LandingEstMinute\", \"TakeOffTimeMinute\", \"CRSDepTimeMinute\", \"CRSArrTimeMinute\", \"DepTimeMinute\",\n",
    "    \"LandingEstHour\", \"TakeOffTimeHour\", \"CRSDepTimeHour\", \"CRSArrTimeHour\", \"DepTimeHour\" #Dividir previamente en hour y minute\n",
    "]\n",
    "\n",
    "\n",
    "# A) Procesamiento de Categóricas (StringIndexer + OHE)\n",
    "input_cols_ohe = []\n",
    "\n",
    "for c in cat_cols:\n",
    "    # 1. Indexar: Convierte strings a índices numéricos\n",
    "    indexer = StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "    \n",
    "    # 2. OHE: Convierte índices a vectores dispersos (sparse vectors)\n",
    "    encoder = OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\")\n",
    "    \n",
    "    # Añadimos pasos al pipeline y guardamos el nombre de la columna de salida\n",
    "    stages += [indexer, encoder]\n",
    "    input_cols_ohe.append(f\"{c}_ohe\")\n",
    "\n",
    "# B) Procesamiento de Numéricas (Assembler + StandardScaler)\n",
    "# Nota: StandardScaler en Spark requiere una columna de tipo Vector, no columnas sueltas.\n",
    "\n",
    "# 1. Agrupar todas las numéricas en un solo vector temporal\n",
    "num_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"num_features_raw\", handleInvalid=\"skip\")\n",
    "stages.append(num_assembler)\n",
    "\n",
    "# 2. Estandarizar ese vector (Media 0, Desviación Estándar 1)\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"num_features_raw\", \n",
    "    outputCol=\"num_features_scaled\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")\n",
    "stages.append(scaler)\n",
    "\n",
    "# C) Ensamblaje Final (Unir OHE + Numéricas Escaladas)\n",
    "\n",
    "# Juntamos las columnas OHE y la columna de numéricas ya escaladas\n",
    "assembler_all_inputs = input_cols_ohe + [\"num_features_scaled\"]\n",
    "\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=assembler_all_inputs, \n",
    "    outputCol=\"features\" # Esta es la columna estándar para modelos ML en Spark\n",
    ")\n",
    "stages.append(assembler_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad5b74",
   "metadata": {},
   "source": [
    "### Baseline model training\n",
    "\n",
    "Three baseline models are trained: `LogisticRegression(max_iter=1000)`, `DecisionTreeClassifier()`, and `MLPClassifier(max_iter=500)`. These models are fitted on the feature-selected and scaled training data. Training multiple models at this stage establishes performance benchmarks for comparison and identifies which algorithms are initially more suitable for the dataset before any tuning is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c251e966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:18.023080Z",
     "start_time": "2025-12-11T19:53:12.054651Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Definición de Modelos\n",
    "dt = DecisionTreeRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "rf = RandomForestRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "gbt = GBTRegressor(labelCol=\"ArrDelay\", featuresCol=\"features\")\n",
    "\n",
    "# Creación de Pipelines (usando concatenación para mayor limpieza)\n",
    "pipeline_dt = Pipeline(stages=stages + [dt])\n",
    "pipeline_rf = Pipeline(stages=stages + [rf])\n",
    "pipeline_gbt = Pipeline(stages=stages + [gbt])\n",
    "\n",
    "# 2. Rejillas de parámetros (ParamGrids)\n",
    "# IMPORTANTE: Los parámetros deben coincidir con la instancia del modelo\n",
    "paramGrid_dt = (ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [5])    # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .addGrid(dt.maxBins, [32])   # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .build())\n",
    "\n",
    "paramGrid_rf = (ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [20])   # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .addGrid(rf.maxDepth, [5])    # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .build())\n",
    "\n",
    "paramGrid_gbt = (ParamGridBuilder()\n",
    "    .addGrid(gbt.maxIter, [10])   # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .addGrid(gbt.maxDepth, [3])    # Puedes añadir mas valores si tienes el musculo tecnico para hacerlo. Nosotros no lo tenemos - La RAM esta muy cara\n",
    "    .build())\n",
    "# 3. CrossValidators\n",
    "# Configuramos el evaluador una sola vez para reutilizarlo\n",
    "evaluador = RegressionEvaluator(labelCol=\"ArrDelay\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "cv_dt = CrossValidator(\n",
    "    estimator=pipeline_dt, \n",
    "    estimatorParamMaps=paramGrid_dt,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "cv_gbt = CrossValidator(\n",
    "    estimator=pipeline_gbt,\n",
    "    estimatorParamMaps=paramGrid_gbt,\n",
    "    evaluator=evaluador,\n",
    "    numFolds=3,\n",
    "    seed=89,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ead558",
   "metadata": {},
   "source": [
    "### Baseline evaluation\n",
    "\n",
    "The `evaluate_full()` function is used to evaluate each model on the test set. It calculates standard metrics including accuracy, precision, recall, and F1-score. It also plots a confusion matrix, the ROC curve with AUC, and the precision-recall curve with AUC-PR. These metrics provide a comprehensive overview of each model's performance and allow for a more nuanced understanding of strengths and weaknesses, especially in cases of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190e246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:53:18.705094Z",
     "start_time": "2025-12-11T19:53:18.032714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Cross-Validation para Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_0 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_2 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_7 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_11 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_6 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_8 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_13 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_4 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_4 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_14 to disk instead.\n",
      "26/01/06 10:53:39 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 237.8 MiB so far)\n",
      "26/01/06 10:53:39 WARN BlockManager: Persisting block rdd_760_5 to disk instead.\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 359.8 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 359.8 MiB so far)\n",
      "26/01/06 10:53:45 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:46 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:47 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:49 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_0 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_7 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_5 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_14 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_8 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_11 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_2 in memory! (computed 159.1 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_6 in memory! (computed 239.9 MiB so far)\n",
      "26/01/06 10:53:50 WARN MemoryStore: Not enough space to cache rdd_760_13 in memory! (computed 359.8 MiB so far)\n",
      "[Stage 322:>                                                      (0 + 16) / 16]\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "modelos_cv = [(\"Decision Tree\", cv_dt), (\"Random Forest\", cv_rf), (\"GBT\", cv_gbt)]\n",
    "resultados = []\n",
    "\n",
    "# Evaluadores\n",
    "eval_mae = RegressionEvaluator(labelCol=\"ArrDelay\", metricName=\"mae\")\n",
    "# 'evaluador' ya lo tienes definido arriba como RMSE\n",
    "\n",
    "for nombre, cv in modelos_cv:\n",
    "    print(f\"Iniciando Cross-Validation para {nombre}...\")\n",
    "    \n",
    "    # 1. AJUSTE DE HIPERPARÁMETROS (Tuning)\n",
    "    # Aquí Spark entrena los 'n' folds y selecciona la mejor combinación de la rejilla\n",
    "    spark.catalog.clearCache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    cv_model = cv.fit(train_data) \n",
    "    \n",
    "    # 2. EVALUACIÓN (Validación con datos no vistos)\n",
    "    # Usamos el cv_model (que ya contiene el mejor modelo interno) para predecir\n",
    "    predicciones = cv_model.transform(test_data)\n",
    "    \n",
    "    rmse = evaluador.evaluate(predicciones) # RMSE\n",
    "    mae = eval_mae.evaluate(predicciones)   # MAE\n",
    "    \n",
    "    # Tu lógica de decisión: Si RMSE es muy alto respecto al MAE, priorizar MAE\n",
    "    score = mae if rmse > (2 * mae) else rmse\n",
    "    metrica_usada = \"MAE\" if rmse > (2 * mae) else \"RMSE\"\n",
    "    \n",
    "    print(f\"Resultados {nombre} -> RMSE: {rmse:.2f}, MAE: {mae:.2f} (Score: {score:.2f} vía {metrica_usada})\")\n",
    "    \n",
    "    # Guardamos todo el objeto cv_model para poder extraer el mejor modelo después\n",
    "    resultados.append({\n",
    "        \"nombre\": nombre,\n",
    "        \"modelo_fit\": cv_model, \n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"score_final\": score,\n",
    "        \"metrica\": metrica_usada\n",
    "    })\n",
    "\n",
    "# --- PASO D: ENCONTRAR Y GUARDAR EL MEJOR ---\n",
    "\n",
    "# Encontrar el mejor resultado basado en tu score_final\n",
    "mejor_resultado = min(resultados, key=lambda x: x[\"score_final\"])\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"GANADOR: {mejor_resultado['nombre']}\")\n",
    "print(f\"Criterio: {mejor_resultado['metrica']} de {mejor_resultado['score_final']:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Extraer el modelo definitivo (el que mejor funcionó en el CV)\n",
    "# Nota: cv_model.bestModel devuelve el PipelineModel con los mejores parámetros\n",
    "mejor_modelo_final = mejor_resultado['modelo_fit'].bestModel\n",
    "\n",
    "# 3. ALMACENAMIENTO DEL MODELO (Requisito del proyecto)\n",
    "path_guardado = \"best_model\"\n",
    "mejor_modelo_final.write().overwrite().save(path_guardado)\n",
    "\n",
    "print(f\"Éxito: El modelo '{mejor_resultado['nombre']}' ha sido guardado en la carpeta '{path_guardado}'\")\n",
    "\n",
    "'''modelos_cv = [(\"Decision Tree\", cv_dt), (\"Random Forest\", cv_rf), (\"GBT\", cv_gbt)]\n",
    "resultados = []\n",
    "\n",
    "eval_mae = RegressionEvaluator(labelCol=\"ArrDelay\", metricName=\"mae\")\n",
    "\n",
    "for nombre, cv in modelos_cv:\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    fit_model = cv.fit(train_data) # train_data debe estar definido previamente\n",
    "    predicciones = fit_model.transform(test_data)\n",
    "    \n",
    "    rmse = evaluador.evaluate(predicciones) # RMSE\n",
    "    mae = eval_mae.evaluate(predicciones)   # MAE\n",
    "    \n",
    "    # Tu lógica: Si RMSE > 2*MAE, fijarse en MAE, si no en RMSE\n",
    "    score = mae if rmse > (2 * mae) else rmse\n",
    "    metrica_usada = \"MAE\" if rmse > (2 * mae) else \"RMSE\"\n",
    "    \n",
    "    resultados.append({\n",
    "        \"nombre\": nombre,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"score_final\": score,\n",
    "        \"metrica\": metrica_usada\n",
    "    })\n",
    "\n",
    "# Encontrar el mejor\n",
    "mejor_modelo = min(resultados, key=lambda x: x[\"score_final\"])\n",
    "print(f\"\\nEl mejor modelo es {mejor_modelo['nombre']} basado en {mejor_modelo['metrica']}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed84ff",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "GridSearchCV is used for hyperparameter optimization for each model: logistic regression (`C`, `penalty`, `solver`), decision tree (`max_depth`, `min_samples_split`), and neural network (`hidden_layer_sizes`, `alpha`). The code searches across multiple parameter combinations with 5-fold cross-validation to select the configuration that maximizes accuracy. This step is essential for improving model generalization and ensuring that the final models perform optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08e961",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "\n",
    "After tuning, the code retrieves the best model via `grid.best_estimator_` and evaluates it on the test set with `accuracy_score` and `classification_report` again. This step confirms how much the optimized model improves over the baseline. Comparing results allows the user to quantify performance gains resulting from hyperparameter optimization and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1c15d",
   "metadata": {},
   "source": [
    "### Interpretability\n",
    "\n",
    "For interpretability, the logistic regression coefficients (betas) are extracted from `best_lr.coef_` and plotted as a horizontal bar chart to visualize the influence of each feature. The decision tree is visualized using `plot_tree()` to show the full branching structure, feature thresholds, Gini impurity, and leaf outcomes. These visualizations help understand how the models make predictions and identify the most important features driving classification decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847bc63",
   "metadata": {},
   "source": [
    "### Comparison Before vs After Tuning\n",
    "\n",
    "This section summarizes the key metrics (accuracy, precision, recall, F1-score) for all three models in a pandas DataFrame. It compares baseline and tuned models side by side, allowing a clear overview of the improvements achieved through feature selection and hyperparameter tuning. This comparative analysis helps identify which model benefits the most from tuning and provides actionable insights for model selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
